name: Daily News Scraper

on:
  schedule:
    # Run every day at 9:00 AM UTC (10:00 AM CET)
    - cron: '0 9 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  scrape-and-generate:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Create data directory
        run: mkdir -p data
      
      - name: Run daily blog automation
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: npm run daily:blog
      
      - name: Check for changes
        id: verify-changed-files
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "changed=true" >> $GITHUB_OUTPUT
          else
            echo "changed=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Commit and push changes
        if: steps.verify-changed-files.outputs.changed == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add .
          git commit -m "ü§ñ Auto-generated blog posts from El Cronista $(date +'%Y-%m-%d')"
          git push
      
      - name: Summary
        run: |
          if [ "${{ steps.verify-changed-files.outputs.changed }}" == "true" ]; then
            echo "‚úÖ New blog posts generated and committed"
          else
            echo "‚ÑπÔ∏è No new articles found to process"
          fi
